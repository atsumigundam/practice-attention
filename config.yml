lstm-self-attention-model:
  epoch: 10
  batch: 100
  embed: 200
  hidden: 10
  lr: 0.01
  dropout: 0.02
  lstm_layers: 1
  max_vocab_size: 32000
  attr_model: ./resources/attr_model
  encoder_model: ./resources/encoder_model
train_file:
  resorces: ./resources/train.txt
train_token_label_file:
  tokens: ./resources/train_token.txt
  labels: ./resources/train_label.txt
save_model_path:
  attr_model: ./resources/attr_model
  encoder_model: ./resources/encoder_model